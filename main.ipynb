{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Document Retrieval\n",
    "\n",
    "This notebook shows the results of document retrieval from different methods (***TF-IDF***, ***BM25*** and ***LLM embedding***) on different pre-processed corpus, i.e ***Lower-Case*** (LC), ***Stopwords Removing*** (SR) and ***Lemmatization*** (L). \n",
    "\n",
    "As mentioned before, the entire corpus has been pre-processed 3 main approach. We created three cleaned dataset, split by languages, using different combination of our chosen approaches. All our datasets can be found on the `clean_data/` folder.\n",
    "\n",
    "1) `lower_case/`: regroup all the cleaned data that have been only pre-processed to split the corpus by languages and lower-case all the text.\n",
    "2) `lower_case_stop_words/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case and remove the stopwords of all text.\n",
    "3) `lower_case_stop_words_lemmatization/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case, remove the stopwords and lemmatization of all text.\n",
    "\n",
    "***Author:*** Paulo Ribeiro"
   ],
   "id": "34e7d539f7f0b1b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import ",
   "id": "e0d144fb04272335"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from data_helpers import QueryClean\n",
    "from models.BM25s.bm25s import BM25sRetriever\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "57f0d1f01f6100fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Queries\n",
    "\n",
    "We load the queries and perform the same pre-processing steps as the corpus."
   ],
   "id": "8b2b6b5387c3eb0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Choose the variables to execute the right pre-process and model to use\n",
    "data_type = 'test'\n",
    "processing_wanted = 'lc_sw_l'\n",
    "k1 = 1.1\n",
    "submission_path = \"\"  # Please refer to where the output.csv needs to go in Kaggle"
   ],
   "id": "6de774113f5841b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the queries\n",
    "query = QueryClean(\n",
    "    queries_path=f'data/{data_type}.csv',\n",
    "    processing_wanted=processing_wanted,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "# Initiate the list to stack all the matches per language in one .csv file\n",
    "match_per_lang = []"
   ],
   "id": "bd9c5539f3eb6d02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform the pre-processing step chosen\n",
    "langs = query.pre_process()"
   ],
   "id": "f613cfccbab5bea7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BM25s\n",
    "\n",
    "Then, we use the improved version of BM25 to compare the performance in our document retrieval task."
   ],
   "id": "587f875c71cc44b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initiate all the BM25s models for each language present in the queries\n",
    "bm25s_retrievers = {\n",
    "    lang: BM25sRetriever(queries_df=query.data_clean[lang],\n",
    "                         model_path=f'models/BM25s/bm25s_matrix/{processing_wanted}/k1_{k1}/bm25s_{lang}.pkl',\n",
    "                         top_k=10)\n",
    "    for lang in langs\n",
    "}"
   ],
   "id": "cc14b665dddbc728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute the matching between query and document for each language separately\n",
    "for lang in langs:\n",
    "    bm25s = bm25s_retrievers[lang]\n",
    "    bm25s.match()\n",
    "    match_per_lang.append(bm25s.matches)"
   ],
   "id": "1eaa323591c22c06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Stack all the pd.Series to create a unified pd.Series with all the matches\n",
    "matches = pd.concat(match_per_lang, ignore_index=True)\n",
    "\n",
    "# Write on disk a .csv file with the matches\n",
    "matches.to_csv(f'{submission_path}/output.csv',\n",
    "               index=True,\n",
    "               index_label='id')"
   ],
   "id": "fc02dd261868bb12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
