{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Document Retrieval\n",
    "\n",
    "This notebook shows the results of document retrieval from different methods (***TF-IDF***, ***BM25*** and ***LLM embedding***) on different pre-processed corpus, i.e ***Lower-Case*** (LC), ***Stopwords Removing*** (SR) and ***Lemmatization*** (L). \n",
    "\n",
    "As mentioned before, the entire corpus has been pre-processed 3 main approach. We created three cleaned dataset, split by languages, using different combination of our chosen approaches. All our datasets can be found on the `clean_data/` folder.\n",
    "\n",
    "1) `lower_case/`: regroup all the cleaned data that have been only pre-processed to split the corpus by languages and lower-case all the text.\n",
    "2) `lower_case_stop_words/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case and remove the stopwords of all text.\n",
    "3) `lower_case_stop_words_lemmatization/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case, remove the stopwords and lemmatization of all text.\n",
    "\n",
    "***Author:*** Paulo Ribeiro"
   ],
   "id": "34e7d539f7f0b1b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import ",
   "id": "e0d144fb04272335"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_helpers import QueryClean\n",
    "from TFIDF.tf_idf import TFIDFRetriever\n",
    "from BM25.bm25 import BM25sRetriever\n",
    "from LLM.llm_embedding import LLMRetriever\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "88e696ee94f6e164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Queries\n",
    "\n",
    "We load the queries and perform the same pre-processing steps as the corpus."
   ],
   "id": "4b5b3eee48edcf10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Choose the pre-process steps to perform.\n",
    "# Please keep the order in that way, while you are allow to delete some pre-process steps:\n",
    "# ['lower_case', 'stop_words', 'lemmatization']\n",
    "process_steps = ['lower_case', 'stop_words', 'lemmatization']\n",
    "\n",
    "# Load the queries\n",
    "query = QueryClean(\n",
    "    queries_path='data/test.csv',\n",
    "    process_steps=process_steps,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "# Variable needed to choose the right model from the pre-process steps chosen before\n",
    "text_pre_processing_desc = '_'.join(process_steps)"
   ],
   "id": "8011f0cdea61b577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform the pre-processing step chosen\n",
    "langs = query.pre_process()"
   ],
   "id": "cdeb90f48584b2c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TF-IDF\n",
    "\n",
    "Let's start by initiate all the TF-IDF retriever for each queries languages."
   ],
   "id": "6e03d4ffc26db47b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tf_idf_retrievers = {\n",
    "    lang: TFIDFRetriever(queries_df=query.data_clean[lang],\n",
    "                         tf_idf_data_path=f'TFIDF/tf_idf_matrix/{text_pre_processing_desc}/tf_idf_{lang}.pkl',\n",
    "                         lang=f'{lang}',\n",
    "                         top_k=10)\n",
    "    for lang in langs\n",
    "}"
   ],
   "id": "71fdd49ccd9200a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Then we can perform the matching process to be able to see the performance of our most basic document retrieval method, using the TF-IDF.",
   "id": "73a05fcfd0960d5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Create script to handle the three methods pipeline to match all multilingual queries with their docids.\n",
    "results = []\n",
    "for lang in langs:\n",
    "    tf_idf = tf_idf_retrievers[lang]\n",
    "    tf_idf.vectorize_query()\n",
    "    tf_idf.match()\n",
    "    results.append(tf_idf.matches)\n",
    "\n",
    "# Stack the results and reset the index\n",
    "stacked_series = pd.concat(results, ignore_index=True)"
   ],
   "id": "be7f40023c7d09d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stacked_series.to_csv('tf_idf_output.csv', index=True, index_label='id')",
   "id": "8cde39368cb4a9ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BM25\n",
    "\n",
    "Then, we use the improved version of TF-IDF to compare the performance in our document retrieval task."
   ],
   "id": "4ee57a7b536aaef9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Create script to handle the three methods pipeline to match all multilingual queries with their docids.\n",
    "bm25_retrievers = {\n",
    "    lang: BM25sRetriever(queries_df=query.data_clean[lang],\n",
    "                         model_path=f'BM25/bm25_matrix/{text_pre_processing_desc}/bm25s_{lang}.pkl',\n",
    "                         top_k=10)\n",
    "    for lang in langs\n",
    "}"
   ],
   "id": "89a7ec668b68064b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for lang in langs:\n",
    "    bm25 = bm25_retrievers[lang]\n",
    "    bm25.match()\n",
    "    results.append(bm25.matches)"
   ],
   "id": "1a254a9fdb72399e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Stack the results and reset the index\n",
    "stacked_series = pd.concat(results, ignore_index=True)"
   ],
   "id": "a468b408ecaef42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stacked_series.to_csv('bm25_output.csv', index=True, index_label='id')",
   "id": "9a7f41c0be5d1021",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LLM Embedding\n",
    "\n",
    "Finally, we use the embeddings of our corpus created by a Large Language Model (LLM) to perform our document retrieval task."
   ],
   "id": "c3061f982dcde123"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pass",
   "id": "4d21bc906b41c034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Performance Comparaison\n",
    "\n",
    "From our three previous methods, we compute their performances using the Recall@10 metric and display the result on a bar chart."
   ],
   "id": "9d01a3eda127fc9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pass",
   "id": "9cda151e0e9f72fd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
