{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Document Retrieval\n",
    "\n",
    "This notebook shows the results of document retrieval from different methods (***TF-IDF***, ***BM25*** and ***LLM embedding***) on different pre-processed corpus, i.e ***Lower-Case*** (LC), ***Stopwords Removing*** (SR) and ***Lemmatization*** (L). \n",
    "\n",
    "As mentioned before, the entire corpus has been pre-processed 3 main approach. We created three cleaned dataset, split by languages, using different combination of our chosen approaches. All our datasets can be found on the `clean_data/` folder.\n",
    "\n",
    "1) `lower_case/`: regroup all the cleaned data that have been only pre-processed to split the corpus by languages and lower-case all the text.\n",
    "2) `lower_case_stop_words/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case and remove the stopwords of all text.\n",
    "3) `lower_case_stop_words_lemmatization/`: regroup all the cleaned data that have been pre-processed to split the corpus by languages, lower-case, remove the stopwords and lemmatization of all text.\n",
    "\n",
    "***Author:*** Paulo Ribeiro"
   ],
   "id": "34e7d539f7f0b1b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import ",
   "id": "e0d144fb04272335"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T00:57:07.406059Z",
     "start_time": "2024-10-17T00:56:54.436037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from data_helpers import QueryClean\n",
    "from TFIDF.tf_idf import TFIDFRetriever\n",
    "from BM25.bm25 import BM25Retriever\n",
    "from LLM.llm_embedding import LLMRetriever\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "88e696ee94f6e164",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Queries\n",
    "\n",
    "We load the queries and perform the same pre-processing steps as the corpus."
   ],
   "id": "4b5b3eee48edcf10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T00:57:07.779861Z",
     "start_time": "2024-10-17T00:57:07.416220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the queries\n",
    "query = QueryClean(queries_path='data/dev.csv')\n",
    "query.split_per_lang()\n",
    "langs = list(query.data_clean.keys())\n",
    "\n",
    "# Perform the pre-processing step wanted by uncommenting the following lines\n",
    "text_pre_processing_desc = 'lower_case_stop_words'\n",
    "query.split_per_lang()\n",
    "query.lower_case()\n",
    "query.stop_words()\n",
    "#query.lemmatization()"
   ],
   "id": "8011f0cdea61b577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading queries...\n",
      "Queries Loaded ! \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'en' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e94a475fa81a4251878ceaeb9ae8f88a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'fr' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b241b20e56ce48a594377aa5a91b99b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'de' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21f49b8e54344124a16f942476e4328b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'es' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f4f05070346499ca32a2a27734fa10a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'it' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d76aef4f2834a049d43c88592fa1de5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'ko' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9384007a8f454780a0353eb5cf93af23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lower casing 'ar' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed88ec10cd5b4de2a85cdbebe35c1de6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'en' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2488659e1e2f467f9ae288cf02f4add6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'fr' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "683ff7898a584a28a99ef72667ab8fbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'de' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b39b30dc86b34c22aa39cbc738cd1c60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'es' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eb467960061443ba392647d78c3c13f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'it' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "742ebe1c076c49eda72f06f6a87177f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Removing stop words for 'ar' texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "045e6aa24bc946fea421cce05f023fa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TF-IDF\n",
    "\n",
    "Let's start by initiate all the TF-IDF retriever for each queries languages."
   ],
   "id": "6e03d4ffc26db47b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T00:57:24.369664Z",
     "start_time": "2024-10-17T00:57:14.053894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf_idf_retrievers = {\n",
    "    lang: TFIDFRetriever(queries_df=query.data_clean[lang],\n",
    "                         tf_idf_data_path=f'TFIDF/tf_idf_matrix/{text_pre_processing_desc}/tf_idf_{lang}.pkl',\n",
    "                         lang=f'{lang}',\n",
    "                         top_k=10) for lang in langs\n",
    "}"
   ],
   "id": "71fdd49ccd9200a9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Then we can perform the matching process to be able to see the performance of our most basic document retrieval method, using the TF-IDF.",
   "id": "73a05fcfd0960d5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T00:58:33.842631Z",
     "start_time": "2024-10-17T00:57:32.948823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for lang in langs:\n",
    "    tf_idf = tf_idf_retrievers[lang]\n",
    "    tf_idf.vectorize_query()\n",
    "    tf_idf.match()\n",
    "    results.append(tf_idf.matches)\n",
    "    \n",
    "# Stack the results and reset the index\n",
    "stacked_series = pd.concat(results, ignore_index=True)"
   ],
   "id": "be7f40023c7d09d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 64369.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 13263.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 34129.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 49128.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 26014.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 31984.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing the TF matrix: 100%|██████████| 200/200 [00:00<00:00, 50610.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix...\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T01:01:10.980663Z",
     "start_time": "2024-10-17T01:01:10.904393Z"
    }
   },
   "cell_type": "code",
   "source": "stacked_series.to_csv('tf_idf_output.csv', index=True)",
   "id": "8cde39368cb4a9ec",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BM25\n",
    "\n",
    "Then, we use the improved version of TF-IDF to compare the performance in our document retrieval task."
   ],
   "id": "4ee57a7b536aaef9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0856333f20fd5fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LLM Embedding\n",
    "\n",
    "Finally, we use the embeddings of our corpus created by a Large Language Model (LLM) to perform our document retrieval task."
   ],
   "id": "c3061f982dcde123"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d21bc906b41c034"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Performance Comparaison\n",
    "\n",
    "From our three previous methods, we compute their performances using the Recall@10 metric and display the result on a bar chart."
   ],
   "id": "9d01a3eda127fc9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9cda151e0e9f72fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
